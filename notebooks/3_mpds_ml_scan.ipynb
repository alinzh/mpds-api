{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "More advanced MPDS API usage: unusual materials phases from the machine learning\n",
    "==========\n",
    "\n",
    "- Complexity level: green karate belt\n",
    "\n",
    "Here we look in MPDS for the \"unusual\" materials phases, _i.e._ these which have the extreme values of more than one physical property. _Extreme_ in this context means close to the either of the prediction boundaries, minimum or maximum.\n",
    "\n",
    "For instance, a crystal with very low Debye temperature, very low enthalpy of formation, very high linear thermal expansion coefficient _etc._ would match. Such cases certainly deserve attention, so let's list them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mpds_client>=0.0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import time\n",
    "import random\n",
    "import threading\n",
    "\n",
    "from mpds_client import MPDSDataRetrieval, MPDSDataTypes\n",
    "\n",
    "ml_data_bounds = {\n",
    "    'isothermal bulk modulus': [5, 265],\n",
    "    'enthalpy of formation': [-325, 0],\n",
    "    'heat capacity at constant pressure': [11, 28],\n",
    "    'Seebeck coefficient': [-150, 225],\n",
    "    'values of electronic band gap': [0.5, 10], # NB stands for both direct + indirect gaps\n",
    "    'temperature for congruent melting': [300, 2700],\n",
    "    'Debye temperature': [175, 1100],\n",
    "    'linear thermal expansion coefficient': [1.0E-06, 9.5E-05]\n",
    "}\n",
    "bound_tolerance_factor = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What's the `bound_tolerance_factor`? For each machine-learning property we divide the entire range of values (_e.g._ from 0 to 1000 THz) into this number. Then we take the first and the last segment. Entries with properties in these segments will be considered **extreme** and kept for the future matching with each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Copy and paste your [MPDS API key](https://mpds.io/open-data-api) in the next cell, then execute. Note, if the key isn't valid, the API returns an HTTP error `403`.\n",
    "\n",
    "Please, make sure not to expose your MPDS key publicly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'YOUR_MPDS_API_KEY_GOES_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes, extremes_intersects = {}, {}\n",
    "\n",
    "def mpds_download_worker(prop, min_bound, max_bound):\n",
    "    '''\n",
    "    A parallel download worker\n",
    "    '''\n",
    "    print(\" Starting with %s\" % prop)\n",
    "\n",
    "    MPDSDataRetrieval.chilouttime = random.randint(3, 4) # please, do not use values < 2\n",
    "    client = MPDSDataRetrieval(dtype=MPDSDataTypes.MACHINE_LEARNING, api_key=API_KEY)\n",
    "\n",
    "    min_entries, max_entries = [], []\n",
    "\n",
    "    for item in client.get_data({\"props\": prop}, fields={'P':[\n",
    "        'sample.material.entry',\n",
    "        'sample.material.phase_id',\n",
    "        'sample.material.chemical_formula',\n",
    "        'sample.measurement[0].property.scalar'\n",
    "    ]}):\n",
    "        if item[3] < min_bound:\n",
    "            min_entries.append(item)\n",
    "\n",
    "        elif item[3] > max_bound:\n",
    "            max_entries.append(item)\n",
    "\n",
    "    for item in list(min_entries) + list(max_entries):\n",
    "\n",
    "        keep_info = [prop, item[0]] + item[2:]\n",
    "\n",
    "        if item[1] in extremes:\n",
    "            extremes_intersects.setdefault(item[1], []).append(keep_info)\n",
    "\n",
    "        else:\n",
    "            extremes[item[1]] = keep_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the most time-consuming step. We need to scan all the machine-learning data. To fetch all the entries for each property requires about 15 minutes. So that will be about 2 hours in total sequentially. We're lucky to parallelize the data extraction using an **mpds_download_worker** for each property, so the total running time will be about half an hour. A reader may grab a cup of tea or coffee (a timely hydration is important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "threads = []\n",
    "for key in ml_data_bounds:\n",
    "\n",
    "    # adjust bounds to match extreme entries\n",
    "    margin = (ml_data_bounds[key][1] - ml_data_bounds[key][0]) / bound_tolerance_factor\n",
    "    ml_data_bounds[key] = [ml_data_bounds[key][0] + margin, ml_data_bounds[key][1] - margin]\n",
    "\n",
    "    # run in parallel, although avoiding too frequent requests\n",
    "    thread = threading.Thread(target=mpds_download_worker, args=[key] + ml_data_bounds[key])\n",
    "    time.sleep(random.randint(1, 5))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "for phase_id in extremes_intersects:\n",
    "    extremes_intersects[phase_id].append(extremes[phase_id])\n",
    "\n",
    "for phase_id in sorted(extremes_intersects.keys()):\n",
    "\n",
    "    print(\"*\" * 30 + \" Distinct phase https://mpds.io/#phase_id/%s \" % system['Phase'] + \"*\" * 30)\n",
    "\n",
    "    for card in extremes_intersects[phase_id]:\n",
    "        print(\"%s (%s) %s = %s %s\" % (card[1], card[0], ))\n",
    "\n",
    "print(\"Done in %1.2f sc\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Were you able to follow everything? Please, try to answer:\n",
    "- How is the value of `bound_tolerance_factor` connected with the total number of results?\n",
    "- How could one obtain the particular crystalline structures for these results?\n",
    "- How could one in principle verify these results?\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
